{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.cbook import boxplot_stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Final.csv\")\n",
    "df.head()\n",
    "df.fillna(\"NaN\", inplace=True)\n",
    "df[\"ORDER_CREATION_DATE\"] = pd.to_datetime(df[\"ORDER_CREATION_DATE\"], format=\"%Y%m%d\")\n",
    "df[\"REQUESTED_DELIVERY_DATE\"] = pd.to_datetime(df[\"REQUESTED_DELIVERY_DATE\"], format=\"%Y%m%d\")\n",
    "df.drop(df[(df[\"ORDER_CREATION_DATE\"] > df[\"REQUESTED_DELIVERY_DATE\"])].index, inplace=True)\n",
    "df[\"ORDER_AMOUNT\"] = df[\"ORDER_AMOUNT\"].str.replace(\"-\", \"\")\n",
    "df[\"ORDER_AMOUNT\"] = df[\"ORDER_AMOUNT\"].str.replace(\",\", \".\")\n",
    "df[\"RELEASED_CREDIT_VALUE\"] = df[\"RELEASED_CREDIT_VALUE\"].str.replace(\"-\", \"\")\n",
    "df[\"RELEASED_CREDIT_VALUE\"] = df[\"RELEASED_CREDIT_VALUE\"].str.replace(\",\", \".\")\n",
    "df[\"ORDER_CURRENCY\"] = df[\"ORDER_CURRENCY\"].replace(\"HU1\", \"HUF\")\n",
    "apikey = \"347adc49463e4adfafd55bba3192ed32\"\n",
    "url = f\"https://openexchangerates.org/api/latest.json?app_id={apikey}\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "exchange_rates = data[\"rates\"]\n",
    "def convert_to_usd(row):\n",
    "    amount = row['ORDER_AMOUNT']\n",
    "    currency = row['ORDER_CURRENCY']\n",
    "    if currency != 'USD':\n",
    "        return float(amount) / exchange_rates.get(currency, 1)\n",
    "    return amount\n",
    "\n",
    "\n",
    "df['amount_in_usd'] = df.apply(convert_to_usd, axis=1)\n",
    "df[\"UNIQUE_CUST_ID\"] = df[\"CUSTOMER_NUMBER\"].astype(str) + df[\"COMPANY_CODE\"].astype(str)\n",
    "df.sort_values('ORDER_CREATION_DATE',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RELEASED_CREDIT_VALUE'] = df['RELEASED_CREDIT_VALUE'].astype(float)\n",
    "df['amount_in_usd']=df['amount_in_usd'].astype(float)\n",
    "df['DISTRIBUTION_CHANNEL'] = df['DISTRIBUTION_CHANNEL'].astype(str)\n",
    "df['DIVISION'] = df['DIVISION'].astype(str)\n",
    "df['PURCHASE_ORDER_TYPE'] = df['PURCHASE_ORDER_TYPE'].astype(str)\n",
    "df['CREDIT_CONTROL_AREA'] = df['CREDIT_CONTROL_AREA'].astype(str)\n",
    "df['CREDIT_STATUS'] = df['CREDIT_STATUS'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ORDER_CREATION_DATE'] = pd.to_datetime(df['ORDER_CREATION_DATE'])\n",
    "df['ORDER_MONTH'] = df['ORDER_CREATION_DATE'].dt.month\n",
    "df['ORDER_DATE'] = df['ORDER_CREATION_DATE'].dt.day\n",
    "monthly_data = {}\n",
    "for month in range(1, 13):\n",
    "    monthly_data[month] = df[df['ORDER_MONTH'] == month]\n",
    "train_data = pd.concat([monthly_data[1],monthly_data[2],monthly_data[3],monthly_data[4]], ignore_index=True)\n",
    "test_data = pd.concat([monthly_data[5],monthly_data[6]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2728/3620527201.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adjusted['ORDER_CREATION_DATE'] = pd.to_datetime(df_adjusted['ORDER_CREATION_DATE'])\n",
      "/tmp/ipykernel_2728/3620527201.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adjusted['ORDER_MONTH'] = df_adjusted['ORDER_CREATION_DATE'].dt.month\n",
      "/tmp/ipykernel_2728/3620527201.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_adjusted['amount_in_usd'].loc[(train_data_adjusted['amount_in_usd'] < lb) | (train_data_adjusted['amount_in_usd'] > ub)]=ub\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1543.9661105132504 2291.5963582239947\n",
      "395.0426580689312\n"
     ]
    }
   ],
   "source": [
    "df_adjusted = df[['UNIQUE_CUST_ID','ORDER_CREATION_DATE','amount_in_usd']]\n",
    "\n",
    "df_adjusted['ORDER_CREATION_DATE'] = pd.to_datetime(df_adjusted['ORDER_CREATION_DATE'])\n",
    "df_adjusted['ORDER_MONTH'] = df_adjusted['ORDER_CREATION_DATE'].dt.month\n",
    "monthly_data = {}\n",
    "for month in range(1, 13):\n",
    "    monthly_data[month] = df_adjusted[df_adjusted['ORDER_MONTH'] == month]\n",
    "train_data_adjusted = pd.concat([monthly_data[1],monthly_data[2],monthly_data[3],monthly_data[4]], ignore_index=True)\n",
    "test_data_adjusted = pd.concat([monthly_data[5],monthly_data[6]], ignore_index=True)\n",
    "\n",
    "Q1 = train_data_adjusted.amount_in_usd.astype(float).quantile(0.25)\n",
    "Q3 = train_data_adjusted.amount_in_usd.astype(float).quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "lb = (Q1-2.2*IQR)\n",
    "ub = (Q3+2.2*IQR)\n",
    "\n",
    "print(str(lb)+\" \"+str(ub))\n",
    "mean_replace = np.mean(train_data_adjusted[~((train_data_adjusted.amount_in_usd.astype(float) < lb) | (train_data_adjusted.amount_in_usd.astype(float) > ub))]['amount_in_usd'].astype(float))\n",
    "print(str(mean_replace))\n",
    "train_data_adjusted['amount_in_usd'].loc[(train_data_adjusted['amount_in_usd'] < lb) | (train_data_adjusted['amount_in_usd'] > ub)]=ub\n",
    "\n",
    "train_data_adjusted = train_data_adjusted.groupby(['UNIQUE_CUST_ID', 'ORDER_CREATION_DATE'], as_index=False).agg({'amount_in_usd': 'sum'})\n",
    "train_data_adjusted.sort_values('ORDER_CREATION_DATE',inplace=True)\n",
    "test_data_adjusted = test_data_adjusted.groupby(['UNIQUE_CUST_ID', 'ORDER_CREATION_DATE'], as_index=False).agg({'amount_in_usd': 'sum'})\n",
    "test_data_adjusted.sort_values('ORDER_CREATION_DATE',inplace=True)\n",
    "\n",
    "# def difference_in_days(melt, lags, ffday, customer_id_col, create_date_col, net_amount_col):\n",
    "#     for i in range(ffday, lags+1):\n",
    "#         melt['Last-'+str(i)+'day_Sales'] = melt.groupby([customer_id_col])[net_amount_col].shift(i)\n",
    "\n",
    "#     melt = melt.reset_index(drop = True)\n",
    "\n",
    "#     for i in range(ffday, lags+1):\n",
    "#         melt['Last-'+str(i)+'day_Diff']  = melt.groupby([customer_id_col])['Last-'+str(i)+'day_Sales'].diff()\n",
    "#     melt = melt.fillna(0)\n",
    "#     return melt\n",
    "\n",
    "# train_data_adjusted = difference_in_days(train_data_adjusted,7,1,'UNIQUE_CUST_ID','ORDER_CREATION_DATE','amount_in_usd')\n",
    "# test_data_adjusted = difference_in_days(test_data_adjusted,7,1,'UNIQUE_CUST_ID','ORDER_CREATION_DATE','amount_in_usd')\n",
    "\n",
    "train_data_adjusted.sort_values(['UNIQUE_CUST_ID', 'ORDER_CREATION_DATE'], ascending=True, inplace=True)\n",
    "\n",
    "for i in range(1, 8):\n",
    "    train_data_adjusted[f'Last-{i}day_Sales'] = pd.NA\n",
    "for index, row in train_data_adjusted.iterrows():\n",
    "    unique_cust_id = row['UNIQUE_CUST_ID']\n",
    "    order_date = row['ORDER_CREATION_DATE']\n",
    "    amount = row['amount_in_usd']\n",
    "    previous_rows = train_data_adjusted.loc[(train_data_adjusted['UNIQUE_CUST_ID'] == unique_cust_id) & (train_data_adjusted['ORDER_CREATION_DATE'] < order_date)]\n",
    "    for i in range(1, 8):\n",
    "        if len(previous_rows) >= i:\n",
    "            train_data_adjusted.at[index, f'Last-{i}day_Sales'] = previous_rows.iloc[-i]['amount_in_usd']\n",
    "\n",
    "for i in range(1, 8):\n",
    "    test_data_adjusted[f'Last-{i}day_Sales'] = pd.NA\n",
    "for index, row in test_data_adjusted.iterrows():\n",
    "    unique_cust_id = row['UNIQUE_CUST_ID']\n",
    "    order_date = row['ORDER_CREATION_DATE']\n",
    "    amount = row['amount_in_usd']\n",
    "    previous_rows = test_data_adjusted.loc[(test_data_adjusted['UNIQUE_CUST_ID'] == unique_cust_id) & (test_data_adjusted['ORDER_CREATION_DATE'] < order_date)]\n",
    "    for i in range(1, 8):\n",
    "        if len(previous_rows) >= i:\n",
    "            test_data_adjusted.at[index, f'Last-{i}day_Sales'] = previous_rows.iloc[-i]['amount_in_usd']\n",
    "\n",
    "\n",
    "train_data = train_data.merge(train_data_adjusted, on=['UNIQUE_CUST_ID', 'ORDER_CREATION_DATE'], how='inner')\n",
    "test_data = test_data.merge(test_data_adjusted, on=['UNIQUE_CUST_ID', 'ORDER_CREATION_DATE'], how='inner')\n",
    "train_data.rename(columns={'amount_in_usd_x': 'amount_in_usd'}, inplace=True)\n",
    "train_data.rename(columns={'amount_in_usd_y': 'net_amount_in_usd'}, inplace=True)\n",
    "test_data.rename(columns={'amount_in_usd_x': 'amount_in_usd'}, inplace=True)\n",
    "test_data.rename(columns={'amount_in_usd_y': 'net_amount_in_usd'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1543.9661105132504 2291.5963582239947\n",
      "395.0426580689312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2728/2223497074.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['amount_in_usd'].loc[(train_data['amount_in_usd'] < lb) | (train_data['amount_in_usd'] > ub)]=ub\n"
     ]
    }
   ],
   "source": [
    "Q1 = train_data.amount_in_usd.astype(float).quantile(0.25)\n",
    "Q3 = train_data.amount_in_usd.astype(float).quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "lb = (Q1-2.2*IQR)\n",
    "ub = (Q3+2.2*IQR)\n",
    "\n",
    "print(str(lb)+\" \"+str(ub))\n",
    "mean_replace = np.mean(train_data[~((train_data.amount_in_usd.astype(float) < lb) | (train_data.amount_in_usd.astype(float) > ub))]['amount_in_usd'].astype(float))\n",
    "print(str(mean_replace))\n",
    "train_data['amount_in_usd'] = train_data['amount_in_usd'].astype(float)\n",
    "test_data['amount_in_usd'] = test_data['amount_in_usd'].astype(float)\n",
    "\n",
    "train_data['amount_in_usd'].loc[(train_data['amount_in_usd'] < lb) | (train_data['amount_in_usd'] > ub)]=ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['EXPECTED_DELIVERY_TIME'] = (train_data['REQUESTED_DELIVERY_DATE'] - train_data['ORDER_CREATION_DATE']).dt.days\n",
    "test_data['EXPECTED_DELIVERY_TIME'] = (test_data['REQUESTED_DELIVERY_DATE'] - test_data['ORDER_CREATION_DATE']).dt.days\n",
    "\n",
    "categorical_columns = ['SALES_ORG', 'DISTRIBUTION_CHANNEL', 'DIVISION', 'CREDIT_CONTROL_AREA', 'CREDIT_STATUS','UNIQUE_CUST_ID']\n",
    "\n",
    "le = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    train_data[column] = le.fit_transform(train_data[column])\n",
    "    dic = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    test_data[column]=test_data[column].map(dic).fillna(6474)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "loop of ufunc does not support argument 0 of type NAType which has no callable log method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'NAType' object has no attribute 'log'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train_data[\u001b[39m'\u001b[39m\u001b[39mRELEASED_CREDIT_VALUE_LOG\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(train_data[\u001b[39m'\u001b[39m\u001b[39mRELEASED_CREDIT_VALUE\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, np\u001b[39m.\u001b[39mlog(train_data[\u001b[39m'\u001b[39m\u001b[39mRELEASED_CREDIT_VALUE\u001b[39m\u001b[39m'\u001b[39m]), train_data[\u001b[39m'\u001b[39m\u001b[39mRELEASED_CREDIT_VALUE\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m train_data[\u001b[39m'\u001b[39m\u001b[39mLast-1day_Sales_log\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(train_data[\u001b[39m'\u001b[39m\u001b[39mLast-1day_Sales\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, np\u001b[39m.\u001b[39;49mlog(train_data[\u001b[39m'\u001b[39;49m\u001b[39mLast-1day_Sales\u001b[39;49m\u001b[39m'\u001b[39;49m]), train_data[\u001b[39m'\u001b[39m\u001b[39mLast-1day_Sales\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m train_data[\u001b[39m'\u001b[39m\u001b[39mLast-2day_Sales_log\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(train_data[\u001b[39m'\u001b[39m\u001b[39mLast-2day_Sales\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, np\u001b[39m.\u001b[39mlog(train_data[\u001b[39m'\u001b[39m\u001b[39mLast-2day_Sales\u001b[39m\u001b[39m'\u001b[39m]), train_data[\u001b[39m'\u001b[39m\u001b[39mLast-2day_Sales\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m train_data[\u001b[39m'\u001b[39m\u001b[39mLast-3day_Sales_log\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(train_data[\u001b[39m'\u001b[39m\u001b[39mLast-3day_Sales\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, np\u001b[39m.\u001b[39mlog(train_data[\u001b[39m'\u001b[39m\u001b[39mLast-3day_Sales\u001b[39m\u001b[39m'\u001b[39m]), train_data[\u001b[39m'\u001b[39m\u001b[39mLast-3day_Sales\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/pandas/core/generic.py:2113\u001b[0m, in \u001b[0;36mNDFrame.__array_ufunc__\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2109\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   2110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array_ufunc__\u001b[39m(\n\u001b[1;32m   2111\u001b[0m     \u001b[39mself\u001b[39m, ufunc: np\u001b[39m.\u001b[39mufunc, method: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39minputs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any\n\u001b[1;32m   2112\u001b[0m ):\n\u001b[0;32m-> 2113\u001b[0m     \u001b[39mreturn\u001b[39;00m arraylike\u001b[39m.\u001b[39;49marray_ufunc(\u001b[39mself\u001b[39;49m, ufunc, method, \u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/pandas/core/arraylike.py:402\u001b[0m, in \u001b[0;36marray_ufunc\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    400\u001b[0m     \u001b[39m# ufunc(series, ...)\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(extract_array(x, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m inputs)\n\u001b[0;32m--> 402\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(ufunc, method)(\u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    403\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m     \u001b[39m# ufunc(dataframe)\u001b[39;00m\n\u001b[1;32m    405\u001b[0m     \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__call__\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs:\n\u001b[1;32m    406\u001b[0m         \u001b[39m# for np.<ufunc>(..) calls\u001b[39;00m\n\u001b[1;32m    407\u001b[0m         \u001b[39m# kwargs cannot necessarily be handled block-by-block, so only\u001b[39;00m\n\u001b[1;32m    408\u001b[0m         \u001b[39m# take this path if there are no kwargs\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: loop of ufunc does not support argument 0 of type NAType which has no callable log method"
     ]
    }
   ],
   "source": [
    "train_data['RELEASED_CREDIT_VALUE_LOG'] = np.where(train_data['RELEASED_CREDIT_VALUE'] > 0, np.log(train_data['RELEASED_CREDIT_VALUE']), train_data['RELEASED_CREDIT_VALUE'])\n",
    "train_data['Last-1day_Sales_log'] = np.where(train_data['Last-1day_Sales'] > 0, np.log(train_data['Last-1day_Sales']), train_data['Last-1day_Sales'])\n",
    "train_data['Last-2day_Sales_log'] = np.where(train_data['Last-2day_Sales'] > 0, np.log(train_data['Last-2day_Sales']), train_data['Last-2day_Sales'])\n",
    "train_data['Last-3day_Sales_log'] = np.where(train_data['Last-3day_Sales'] > 0, np.log(train_data['Last-3day_Sales']), train_data['Last-3day_Sales'])\n",
    "train_data['Last-4day_Sales_log'] = np.where(train_data['Last-4day_Sales'] > 0, np.log(train_data['Last-4day_Sales']), train_data['Last-4day_Sales'])\n",
    "train_data['Last-5day_Sales_log'] = np.where(train_data['Last-5day_Sales'] > 0, np.log(train_data['Last-5day_Sales']), train_data['Last-5day_Sales'])\n",
    "train_data['Last-6day_Sales_log'] = np.where(train_data['Last-6day_Sales'] > 0, np.log(train_data['Last-6day_Sales']), train_data['Last-6day_Sales'])\n",
    "train_data['Last-7day_Sales_log'] = np.where(train_data['Last-7day_Sales'] > 0, np.log(train_data['Last-7day_Sales']), train_data['Last-7day_Sales'])\n",
    "\n",
    "\n",
    "train_data['Last-1day_Sales_log'].fillna(0, inplace=True)\n",
    "train_data['Last-2day_Sales_log'].fillna(0, inplace=True)\n",
    "train_data['Last-3day_Sales_log'].fillna(0, inplace=True)\n",
    "train_data['Last-4day_Sales_log'].fillna(0, inplace=True)\n",
    "train_data['Last-5day_Sales_log'].fillna(0, inplace=True)\n",
    "train_data['Last-6day_Sales_log'].fillna(0, inplace=True)\n",
    "train_data['Last-7day_Sales_log'].fillna(0, inplace=True)\n",
    "\n",
    "test_data['RELEASED_CREDIT_VALUE_LOG'] = np.where(test_data['RELEASED_CREDIT_VALUE'] > 0, np.log(test_data['RELEASED_CREDIT_VALUE']), test_data['RELEASED_CREDIT_VALUE'])\n",
    "test_data['Last-1day_Sales_log'] = np.where(test_data['Last-1day_Sales'] > 0, np.log(test_data['Last-1day_Sales']), test_data['Last-1day_Sales'])\n",
    "test_data['Last-2day_Sales_log'] = np.where(test_data['Last-2day_Sales'] > 0, np.log(test_data['Last-2day_Sales']), test_data['Last-2day_Sales'])\n",
    "test_data['Last-3day_Sales_log'] = np.where(test_data['Last-3day_Sales'] > 0, np.log(test_data['Last-3day_Sales']), test_data['Last-3day_Sales'])\n",
    "test_data['Last-4day_Sales_log'] = np.where(test_data['Last-4day_Sales'] > 0, np.log(test_data['Last-4day_Sales']), test_data['Last-4day_Sales'])\n",
    "test_data['Last-5day_Sales_log'] = np.where(test_data['Last-5day_Sales'] > 0, np.log(test_data['Last-5day_Sales']), test_data['Last-5day_Sales'])\n",
    "test_data['Last-6day_Sales_log'] = np.where(test_data['Last-6day_Sales'] > 0, np.log(test_data['Last-6day_Sales']), test_data['Last-6day_Sales'])\n",
    "test_data['Last-7day_Sales_log'] = np.where(test_data['Last-7day_Sales'] > 0, np.log(test_data['Last-7day_Sales']), test_data['Last-7day_Sales'])\n",
    "\n",
    "\n",
    "\n",
    "test_data['Last-1day_Sales_log'].fillna(0, inplace=True)\n",
    "test_data['Last-2day_Sales_log'].fillna(0, inplace=True)\n",
    "test_data['Last-3day_Sales_log'].fillna(0, inplace=True)\n",
    "test_data['Last-4day_Sales_log'].fillna(0, inplace=True)\n",
    "test_data['Last-5day_Sales_log'].fillna(0, inplace=True)\n",
    "test_data['Last-6day_Sales_log'].fillna(0, inplace=True)\n",
    "test_data['Last-7day_Sales_log'].fillna(0, inplace=True)\n",
    "\n",
    "train_data['amount_in_usd_log'] = np.where(train_data['amount_in_usd'] > 0, np.log(train_data['amount_in_usd']), train_data['amount_in_usd'])\n",
    "test_data['amount_in_usd_log'] = np.where(test_data['amount_in_usd'] > 0, np.log(test_data['amount_in_usd']), test_data['amount_in_usd'])\n",
    "\n",
    "train_data['net_amount_in_usd_log'] = np.where(train_data['net_amount_in_usd'] > 0, np.log(train_data['net_amount_in_usd']), train_data['net_amount_in_usd'])\n",
    "test_data['net_amount_in_usd_log'] = np.where(test_data['net_amount_in_usd'] > 0, np.log(test_data['net_amount_in_usd']), test_data['net_amount_in_usd'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = ['ORDER_DATE','ORDER_MONTH','RELEASED_CREDIT_VALUE_LOG','net_amount_in_usd_log','EXPECTED_DELIVERY_TIME','SALES_ORG', 'DISTRIBUTION_CHANNEL', 'DIVISION', 'CREDIT_CONTROL_AREA','Last-1day_Sales_log','Last-2day_Sales_log','Last-3day_Sales_log','Last-4day_Sales_log','Last-5day_Sales_log','Last-6day_Sales_log','Last-7day_Sales_log']\n",
    "\n",
    "target = 'amount_in_usd_log'\n",
    "X_train = train_data[features]\n",
    "X_test = test_data[features]\n",
    "y_train = train_data[target]\n",
    "y_test = test_data[target]\n",
    "r2_train_list = []\n",
    "r2_test_list = []\n",
    "mse_train_list = []\n",
    "mse_test_list = []\n",
    "rmse_train_list = []\n",
    "rmse_test_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - R-squared Score: 0.42441501103384105\n",
      "Train - Mean Squared Error: 4.230591399718808\n",
      "Test - R-squared Score: 0.27712358552254623\n",
      "Test - Mean Squared Error: 6.282473200604795\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "r2_train_list.append(r2_train)\n",
    "r2_test_list.append(r2_test)\n",
    "mse_train_list.append(mse_train)\n",
    "mse_test_list.append(mse_test)\n",
    "rmse_train_list.append(rmse_train)\n",
    "rmse_test_list.append(rmse_test)\n",
    "\n",
    "print(\"Train - R-squared Score:\", r2_train)\n",
    "print(\"Train - Mean Squared Error:\", mse_train)\n",
    "print(\"Test - R-squared Score:\", r2_test)\n",
    "print(\"Test - Mean Squared Error:\", mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2970\n",
      "[LightGBM] [Info] Number of data points in the train set: 855281, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 4.583369\n",
      "Train - R-squared Score: 0.8045358482005713\n",
      "Train - Mean Squared Error: 1.436675687184422\n",
      "Test - R-squared Score: 0.3033606708219597\n",
      "Test - Mean Squared Error: 6.054448351606643\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'num_leaves': 80, #80-100\n",
    "    'learning_rate': 0.05, #.06 -.07\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 6,#3-5\n",
    "    'verbose': 1\n",
    "}\n",
    "model = lgb.train(params,train_data,num_boost_round=1000)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"Train - R-squared Score:\", r2_train)\n",
    "print(\"Train - Mean Squared Error:\", mse_train)\n",
    "print(\"Test - R-squared Score:\", r2_test)\n",
    "print(\"Test - Mean Squared Error:\", mse_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
