{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.cbook import boxplot_stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Final.csv\")\n",
    "df.head()\n",
    "df.fillna(\"NaN\", inplace=True)\n",
    "df[\"ORDER_CREATION_DATE\"] = pd.to_datetime(df[\"ORDER_CREATION_DATE\"], format=\"%Y%m%d\")\n",
    "df[\"REQUESTED_DELIVERY_DATE\"] = pd.to_datetime(df[\"REQUESTED_DELIVERY_DATE\"], format=\"%Y%m%d\")\n",
    "df.drop(df[(df[\"ORDER_CREATION_DATE\"] > df[\"REQUESTED_DELIVERY_DATE\"])].index, inplace=True)\n",
    "df[\"ORDER_AMOUNT\"] = df[\"ORDER_AMOUNT\"].str.replace(\"-\", \"\")\n",
    "df[\"ORDER_AMOUNT\"] = df[\"ORDER_AMOUNT\"].str.replace(\",\", \".\")\n",
    "df[\"RELEASED_CREDIT_VALUE\"] = df[\"RELEASED_CREDIT_VALUE\"].str.replace(\"-\", \"\")\n",
    "df[\"RELEASED_CREDIT_VALUE\"] = df[\"RELEASED_CREDIT_VALUE\"].str.replace(\",\", \".\")\n",
    "df[\"ORDER_CURRENCY\"] = df[\"ORDER_CURRENCY\"].replace(\"HU1\", \"HUF\")\n",
    "apikey = \"347adc49463e4adfafd55bba3192ed32\"\n",
    "url = f\"https://openexchangerates.org/api/latest.json?app_id={apikey}\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "exchange_rates = data[\"rates\"]\n",
    "def convert_to_usd(row):\n",
    "    amount = row['ORDER_AMOUNT']\n",
    "    currency = row['ORDER_CURRENCY']\n",
    "    if currency != 'USD':\n",
    "        return float(amount) / exchange_rates.get(currency, 1)\n",
    "    return amount\n",
    "\n",
    "\n",
    "df['amount_in_usd'] = df.apply(convert_to_usd, axis=1)\n",
    "df[\"UNIQUE_CUST_ID\"] = df[\"CUSTOMER_NUMBER\"].astype(str) + df[\"COMPANY_CODE\"].astype(str)\n",
    "df = df.sort_values('ORDER_CREATION_DATE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amount_in_usd']=df['amount_in_usd'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjusted = df[['UNIQUE_CUST_ID','ORDER_CREATION_DATE','amount_in_usd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44079/1382338643.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adjusted['ORDER_CREATION_DATE'] = pd.to_datetime(df_adjusted['ORDER_CREATION_DATE'])\n",
      "/tmp/ipykernel_44079/1382338643.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adjusted['ORDER_MONTH'] = df_adjusted['ORDER_CREATION_DATE'].dt.month\n"
     ]
    }
   ],
   "source": [
    "df_adjusted['ORDER_CREATION_DATE'] = pd.to_datetime(df_adjusted['ORDER_CREATION_DATE'])\n",
    "df_adjusted['ORDER_MONTH'] = df_adjusted['ORDER_CREATION_DATE'].dt.month\n",
    "monthly_data = {}\n",
    "for month in range(1, 13):\n",
    "    monthly_data[month] = df_adjusted[df_adjusted['ORDER_MONTH'] == month]\n",
    "train_data_adjusted = pd.concat([monthly_data[1],monthly_data[2],monthly_data[3],monthly_data[4]], ignore_index=True)\n",
    "test_data_adjusted = pd.concat([monthly_data[5],monthly_data[6]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1544.070207451883 2291.698142009741\n",
      "395.03193125009534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44079/1538298103.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_adjusted['amount_in_usd'].loc[(train_data_adjusted['amount_in_usd'] < lb) | (train_data_adjusted['amount_in_usd'] > ub)]=ub\n"
     ]
    }
   ],
   "source": [
    "Q1 = train_data_adjusted.amount_in_usd.astype(float).quantile(0.25)\n",
    "Q3 = train_data_adjusted.amount_in_usd.astype(float).quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "lb = (Q1-2.2*IQR)\n",
    "ub = (Q3+2.2*IQR)\n",
    "\n",
    "print(str(lb)+\" \"+str(ub))\n",
    "mean_replace = np.mean(train_data_adjusted[~((train_data_adjusted.amount_in_usd.astype(float) < lb) | (train_data_adjusted.amount_in_usd.astype(float) > ub))]['amount_in_usd'].astype(float))\n",
    "print(str(mean_replace))\n",
    "train_data_adjusted['amount_in_usd'] = train_data_adjusted['amount_in_usd'].astype(float)\n",
    "test_data_adjusted['amount_in_usd'] = test_data_adjusted['amount_in_usd'].astype(float)\n",
    "\n",
    "train_data_adjusted['amount_in_usd'].loc[(train_data_adjusted['amount_in_usd'] < lb) | (train_data_adjusted['amount_in_usd'] > ub)]=ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIQUE_CUST_ID</th>\n",
       "      <th>ORDER_CREATION_DATE</th>\n",
       "      <th>amount_in_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20314</th>\n",
       "      <td>12104172983000</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>1663.130243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38307</th>\n",
       "      <td>123001123350</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>416.977414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21318</th>\n",
       "      <td>12104312003030</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>746.491071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51983</th>\n",
       "      <td>123118073220</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>1874.676473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21196</th>\n",
       "      <td>12104307433030</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>1115.045908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UNIQUE_CUST_ID ORDER_CREATION_DATE  amount_in_usd\n",
       "20314  12104172983000          2022-01-01    1663.130243\n",
       "38307    123001123350          2022-01-01     416.977414\n",
       "21318  12104312003030          2022-01-01     746.491071\n",
       "51983    123118073220          2022-01-01    1874.676473\n",
       "21196  12104307433030          2022-01-01    1115.045908"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_adjusted = train_data_adjusted.groupby(['UNIQUE_CUST_ID', 'ORDER_CREATION_DATE'], as_index=False).agg({'amount_in_usd': 'sum'})\n",
    "train_data_adjusted = train_data_adjusted.sort_values('ORDER_CREATION_DATE')\n",
    "train_data_adjusted.head()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIQUE_CUST_ID</th>\n",
       "      <th>ORDER_CREATION_DATE</th>\n",
       "      <th>amount_in_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4061</th>\n",
       "      <td>12103577693000</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>1114.588043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2944</th>\n",
       "      <td>12101795693260</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4640</th>\n",
       "      <td>12104088433030</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>353.337830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>12103494423000</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>186.617381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>12101784533000</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>152.713990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      UNIQUE_CUST_ID ORDER_CREATION_DATE  amount_in_usd\n",
       "4061  12103577693000          2022-05-01    1114.588043\n",
       "2944  12101795693260          2022-05-01       0.000000\n",
       "4640  12104088433030          2022-05-01     353.337830\n",
       "3921  12103494423000          2022-05-01     186.617381\n",
       "2935  12101784533000          2022-05-01     152.713990"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_adjusted = test_data_adjusted.groupby(['UNIQUE_CUST_ID', 'ORDER_CREATION_DATE'], as_index=False).agg({'amount_in_usd': 'sum'})\n",
    "test_data_adjusted = test_data_adjusted.sort_values('ORDER_CREATION_DATE')\n",
    "test_data_adjusted.head()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_in_days(melt, lags, ffday, customer_id_col, create_date_col, net_amount_col):\n",
    "    for i in range(ffday, lags+1):\n",
    "        melt['Last-'+str(i)+'day_Sales'] = melt.groupby([customer_id_col])[net_amount_col].shift(i)\n",
    "\n",
    "    melt = melt.reset_index(drop = True)\n",
    "\n",
    "    for i in range(ffday, lags+1):\n",
    "        melt['Last-'+str(i)+'day_Diff']  = melt.groupby([customer_id_col])['Last-'+str(i)+'day_Sales'].diff()\n",
    "    melt = melt.fillna(0)\n",
    "    return melt\n",
    "\n",
    "train_data_adjusted = difference_in_days(train_data_adjusted,7,1,'UNIQUE_CUST_ID','ORDER_CREATION_DATE','amount_in_usd')\n",
    "test_data_adjusted = difference_in_days(test_data_adjusted,7,1,'UNIQUE_CUST_ID','ORDER_CREATION_DATE','amount_in_usd')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UNIQUE_CUST_ID', 'ORDER_CREATION_DATE', 'amount_in_usd',\n",
       "       'Last-1day_Sales', 'Last-2day_Sales', 'Last-3day_Sales',\n",
       "       'Last-4day_Sales', 'Last-5day_Sales', 'Last-6day_Sales',\n",
       "       'Last-7day_Sales', 'Last-1day_Diff', 'Last-2day_Diff', 'Last-3day_Diff',\n",
       "       'Last-4day_Diff', 'Last-5day_Diff', 'Last-6day_Diff', 'Last-7day_Diff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_adjusted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CUSTOMER_ORDER_ID', 'SALES_ORG', 'DISTRIBUTION_CHANNEL', 'DIVISION',\n",
       "       'RELEASED_CREDIT_VALUE', 'PURCHASE_ORDER_TYPE', 'COMPANY_CODE',\n",
       "       'ORDER_CREATION_DATE', 'ORDER_CREATION_TIME', 'CREDIT_CONTROL_AREA',\n",
       "       'SOLD_TO_PARTY', 'ORDER_AMOUNT', 'REQUESTED_DELIVERY_DATE',\n",
       "       'ORDER_CURRENCY', 'CREDIT_STATUS', 'CUSTOMER_NUMBER', 'amount_in_usd',\n",
       "       'UNIQUE_CUST_ID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ORDER_CREATION_DATE'] = pd.to_datetime(df['ORDER_CREATION_DATE'])\n",
    "df['ORDER_MONTH'] = df['ORDER_CREATION_DATE'].dt.month\n",
    "monthly_data = {}\n",
    "for month in range(1, 13):\n",
    "    monthly_data[month] = df[df['ORDER_MONTH'] == month]\n",
    "train_data = pd.concat([monthly_data[1],monthly_data[2],monthly_data[3],monthly_data[4]], ignore_index=True)\n",
    "test_data = pd.concat([monthly_data[5],monthly_data[6]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.merge(train_data_adjusted, on=['UNIQUE_CUST_ID', 'ORDER_CREATION_DATE'], how='inner')\n",
    "test_data = test_data.merge(test_data_adjusted, on=['UNIQUE_CUST_ID', 'ORDER_CREATION_DATE'], how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.rename(columns={'amount_in_usd_x': 'amount_in_usd'}, inplace=True)\n",
    "train_data.rename(columns={'amount_in_usd_y': 'net_amount_in_usd'}, inplace=True)\n",
    "\n",
    "test_data.rename(columns={'amount_in_usd_x': 'amount_in_usd'}, inplace=True)\n",
    "test_data.rename(columns={'amount_in_usd_y': 'net_amount_in_usd'}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1544.070207451883 2291.698142009741\n",
      "395.0319312500955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44079/1295402488.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['amount_in_usd'].loc[(train_data['amount_in_usd'] < lb) | (train_data['amount_in_usd'] > ub)]=ub\n"
     ]
    }
   ],
   "source": [
    "Q1 = train_data.amount_in_usd.astype(float).quantile(0.25)\n",
    "Q3 = train_data.amount_in_usd.astype(float).quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "lb = (Q1-2.2*IQR)\n",
    "ub = (Q3+2.2*IQR)\n",
    "\n",
    "print(str(lb)+\" \"+str(ub))\n",
    "mean_replace = np.mean(train_data[~((train_data.amount_in_usd.astype(float) < lb) | (train_data.amount_in_usd.astype(float) > ub))]['amount_in_usd'].astype(float))\n",
    "print(str(mean_replace))\n",
    "train_data['amount_in_usd'] = train_data['amount_in_usd'].astype(float)\n",
    "test_data['amount_in_usd'] = test_data['amount_in_usd'].astype(float)\n",
    "\n",
    "train_data['amount_in_usd'].loc[(train_data['amount_in_usd'] < lb) | (train_data['amount_in_usd'] > ub)]=ub\n",
    "# test_data['amount_in_usd'].loc[(test_data['amount_in_usd'] < lb) | (test_data['amount_in_usd'] > ub)]=mean_replace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['DISTRIBUTION_CHANNEL'] = train_data['DISTRIBUTION_CHANNEL'].astype(str)\n",
    "train_data['DIVISION'] = train_data['DIVISION'].astype(str)\n",
    "train_data['PURCHASE_ORDER_TYPE'] = train_data['PURCHASE_ORDER_TYPE'].astype(str)\n",
    "train_data['CREDIT_CONTROL_AREA'] = train_data['CREDIT_CONTROL_AREA'].astype(str)\n",
    "train_data['CREDIT_STATUS'] = train_data['CREDIT_STATUS'].astype(str)\n",
    "\n",
    "test_data['DISTRIBUTION_CHANNEL'] = test_data['DISTRIBUTION_CHANNEL'].astype(str)\n",
    "test_data['DIVISION'] = test_data['DIVISION'].astype(str)\n",
    "test_data['PURCHASE_ORDER_TYPE'] = test_data['PURCHASE_ORDER_TYPE'].astype(str)\n",
    "test_data['CREDIT_CONTROL_AREA'] = test_data['CREDIT_CONTROL_AREA'].astype(str)\n",
    "test_data['CREDIT_STATUS'] = test_data['CREDIT_STATUS'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['EXPECTED_DELIVERY_TIME'] = (train_data['REQUESTED_DELIVERY_DATE'] - train_data['ORDER_CREATION_DATE']).dt.days\n",
    "test_data['EXPECTED_DELIVERY_TIME'] = (test_data['REQUESTED_DELIVERY_DATE'] - test_data['ORDER_CREATION_DATE']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical_columns = ['SALES_ORG', 'DISTRIBUTION_CHANNEL', 'DIVISION', 'CREDIT_CONTROL_AREA', 'CREDIT_STATUS','UNIQUE_CUST_ID']\n",
    "# label_encoder = LabelEncoder()\n",
    "# for column in categorical_columns:\n",
    "#     label_encoder.fit(train_data[column])\n",
    "#     train_data[column] = label_encoder.transform(train_data[column].astype(str))\n",
    "#     test_data[column] = label_encoder.transform(test_data[column].astype(str))\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    train_data[column] = le.fit_transform(train_data[column])\n",
    "    dic = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    test_data[column]=test_data[column].map(dic).fillna(6474)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUSTOMER_ORDER_ID          0\n",
       "SALES_ORG                  0\n",
       "DISTRIBUTION_CHANNEL       0\n",
       "DIVISION                   0\n",
       "RELEASED_CREDIT_VALUE      0\n",
       "PURCHASE_ORDER_TYPE        0\n",
       "COMPANY_CODE               0\n",
       "ORDER_CREATION_DATE        0\n",
       "ORDER_CREATION_TIME        0\n",
       "CREDIT_CONTROL_AREA        0\n",
       "SOLD_TO_PARTY              0\n",
       "ORDER_AMOUNT               0\n",
       "REQUESTED_DELIVERY_DATE    0\n",
       "ORDER_CURRENCY             0\n",
       "CREDIT_STATUS              0\n",
       "CUSTOMER_NUMBER            0\n",
       "amount_in_usd              0\n",
       "UNIQUE_CUST_ID             0\n",
       "ORDER_MONTH                0\n",
       "net_amount_in_usd          0\n",
       "Last-1day_Sales            0\n",
       "Last-2day_Sales            0\n",
       "Last-3day_Sales            0\n",
       "Last-4day_Sales            0\n",
       "Last-5day_Sales            0\n",
       "Last-6day_Sales            0\n",
       "Last-7day_Sales            0\n",
       "Last-1day_Diff             0\n",
       "Last-2day_Diff             0\n",
       "Last-3day_Diff             0\n",
       "Last-4day_Diff             0\n",
       "Last-5day_Diff             0\n",
       "Last-6day_Diff             0\n",
       "Last-7day_Diff             0\n",
       "EXPECTED_DELIVERY_TIME     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[test_data[['SALES_ORG', 'DISTRIBUTION_CHANNEL', 'DIVISION', 'CREDIT_CONTROL_AREA', 'CREDIT_STATUS','UNIQUE_CUST_ID']]==\"NaN\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def difference_in_days(melt, lags, ffday, customer_id_col, create_date_col, net_amount_col):\n",
    "#     for i in range(ffday, lags+1):\n",
    "#         melt['Last-'+str(i)+'day_Sales'] = melt.groupby([customer_id_col])[net_amount_col].shift(i)\n",
    "\n",
    "#     melt = melt.reset_index(drop = True)\n",
    "\n",
    "#     for i in range(ffday, lags+1):\n",
    "#         melt['Last-'+str(i)+'day_Diff']  = melt.groupby([customer_id_col])['Last-'+str(i)+'day_Sales'].diff()\n",
    "#     melt = melt.fillna(0)\n",
    "#     return melt\n",
    "\n",
    "# train_data = difference_in_days(train_data,7,1,'UNIQUE_CUST_ID','ORDER_CREATION_DATE','NET_AMOUNT_PER_DAY')\n",
    "# test_data = difference_in_days(test_data,7,1,'UNIQUE_CUST_ID','ORDER_CREATION_DATE','NET_AMOUNT_PER_DAY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_data['RELEASED_CREDIT_VALUE'] = train_data['RELEASED_CREDIT_VALUE'].astype(float)\n",
    "train_data['RELEASED_CREDIT_VALUE_LOG'] = np.where(train_data['RELEASED_CREDIT_VALUE'] > 0, np.log(train_data['RELEASED_CREDIT_VALUE']), train_data['RELEASED_CREDIT_VALUE'])\n",
    "train_data['Last-1day_Sales_log'] = np.where(train_data['Last-1day_Sales'] > 0, np.log(train_data['Last-1day_Sales']), train_data['Last-1day_Sales'])\n",
    "train_data['Last-2day_Sales_log'] = np.where(train_data['Last-2day_Sales'] > 0, np.log(train_data['Last-2day_Sales']), train_data['Last-2day_Sales'])\n",
    "train_data['Last-3day_Sales_log'] = np.where(train_data['Last-3day_Sales'] > 0, np.log(train_data['Last-3day_Sales']), train_data['Last-3day_Sales'])\n",
    "train_data['Last-4day_Sales_log'] = np.where(train_data['Last-4day_Sales'] > 0, np.log(train_data['Last-4day_Sales']), train_data['Last-4day_Sales'])\n",
    "train_data['Last-5day_Sales_log'] = np.where(train_data['Last-5day_Sales'] > 0, np.log(train_data['Last-5day_Sales']), train_data['Last-5day_Sales'])\n",
    "train_data['Last-6day_Sales_log'] = np.where(train_data['Last-6day_Sales'] > 0, np.log(train_data['Last-6day_Sales']), train_data['Last-6day_Sales'])\n",
    "train_data['Last-7day_Sales_log'] = np.where(train_data['Last-7day_Sales'] > 0, np.log(train_data['Last-7day_Sales']), train_data['Last-7day_Sales'])\n",
    "\n",
    "\n",
    "train_data['Last-1day_Sales_log'].fillna(0, inplace=True)\n",
    "train_data['Last-2day_Sales_log'].fillna(0, inplace=True)\n",
    "train_data['Last-3day_Sales_log'].fillna(0, inplace=True)\n",
    "train_data['Last-4day_Sales_log'].fillna(0, inplace=True)\n",
    "train_data['Last-5day_Sales_log'].fillna(0, inplace=True)\n",
    "train_data['Last-6day_Sales_log'].fillna(0, inplace=True)\n",
    "train_data['Last-7day_Sales_log'].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "test_data['RELEASED_CREDIT_VALUE'] = test_data['RELEASED_CREDIT_VALUE'].astype(float)\n",
    "test_data['RELEASED_CREDIT_VALUE_LOG'] = np.where(test_data['RELEASED_CREDIT_VALUE'] > 0, np.log(test_data['RELEASED_CREDIT_VALUE']), test_data['RELEASED_CREDIT_VALUE'])\n",
    "test_data['Last-1day_Sales_log'] = np.where(test_data['Last-1day_Sales'] > 0, np.log(test_data['Last-1day_Sales']), test_data['Last-1day_Sales'])\n",
    "test_data['Last-2day_Sales_log'] = np.where(test_data['Last-2day_Sales'] > 0, np.log(test_data['Last-2day_Sales']), test_data['Last-2day_Sales'])\n",
    "test_data['Last-3day_Sales_log'] = np.where(test_data['Last-3day_Sales'] > 0, np.log(test_data['Last-3day_Sales']), test_data['Last-3day_Sales'])\n",
    "test_data['Last-4day_Sales_log'] = np.where(test_data['Last-4day_Sales'] > 0, np.log(test_data['Last-4day_Sales']), test_data['Last-4day_Sales'])\n",
    "test_data['Last-5day_Sales_log'] = np.where(test_data['Last-5day_Sales'] > 0, np.log(test_data['Last-5day_Sales']), test_data['Last-5day_Sales'])\n",
    "test_data['Last-6day_Sales_log'] = np.where(test_data['Last-6day_Sales'] > 0, np.log(test_data['Last-6day_Sales']), test_data['Last-6day_Sales'])\n",
    "test_data['Last-7day_Sales_log'] = np.where(test_data['Last-7day_Sales'] > 0, np.log(test_data['Last-7day_Sales']), test_data['Last-7day_Sales'])\n",
    "\n",
    "\n",
    "\n",
    "test_data['Last-1day_Sales_log'].fillna(0, inplace=True)\n",
    "test_data['Last-2day_Sales_log'].fillna(0, inplace=True)\n",
    "test_data['Last-3day_Sales_log'].fillna(0, inplace=True)\n",
    "test_data['Last-4day_Sales_log'].fillna(0, inplace=True)\n",
    "test_data['Last-5day_Sales_log'].fillna(0, inplace=True)\n",
    "test_data['Last-6day_Sales_log'].fillna(0, inplace=True)\n",
    "test_data['Last-7day_Sales_log'].fillna(0, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_data['amount_in_usd_log'] = np.where(train_data['amount_in_usd'] > 0, np.log(train_data['amount_in_usd']), train_data['amount_in_usd'])\n",
    "test_data['amount_in_usd_log'] = np.where(test_data['amount_in_usd'] > 0, np.log(test_data['amount_in_usd']), test_data['amount_in_usd'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_data['net_amount_in_usd_log'] = np.where(train_data['net_amount_in_usd'] > 0, np.log(train_data['net_amount_in_usd']), train_data['net_amount_in_usd'])\n",
    "test_data['net_amount_in_usd_log'] = np.where(test_data['net_amount_in_usd'] > 0, np.log(test_data['net_amount_in_usd']), test_data['net_amount_in_usd'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['ORDER_CREATION_DATE'] = train_data['ORDER_CREATION_DATE'].astype(int)\n",
    "test_data['ORDER_CREATION_DATE'] = test_data['ORDER_CREATION_DATE'].astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = ['RELEASED_CREDIT_VALUE_LOG','UNIQUE_CUST_ID','EXPECTED_DELIVERY_TIME','SALES_ORG', 'DISTRIBUTION_CHANNEL', 'DIVISION', 'CREDIT_CONTROL_AREA', 'CREDIT_STATUS','Last-1day_Sales_log','Last-2day_Sales_log','Last-3day_Sales_log','Last-4day_Sales_log','Last-5day_Sales_log','Last-6day_Sales_log','Last-7day_Sales_log']\n",
    "\n",
    "target = 'amount_in_usd_log'\n",
    "X_train = train_data[features]\n",
    "X_test = test_data[features]\n",
    "y_train = train_data[target]\n",
    "y_test = test_data[target]\n",
    "r2_train_list = []\n",
    "r2_test_list = []\n",
    "mse_train_list = []\n",
    "mse_test_list = []\n",
    "rmse_train_list = []\n",
    "rmse_test_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - R-squared Score: 0.17047885475898295\n",
      "Train - Mean Squared Error: 6.097019234883232\n",
      "Test - R-squared Score: 0.11760918863790326\n",
      "Test - Mean Squared Error: 7.668679674648252\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "r2_train_list.append(r2_train)\n",
    "r2_test_list.append(r2_test)\n",
    "mse_train_list.append(mse_train)\n",
    "mse_test_list.append(mse_test)\n",
    "rmse_train_list.append(rmse_train)\n",
    "rmse_test_list.append(rmse_test)\n",
    "\n",
    "print(\"Train - R-squared Score:\", r2_train)\n",
    "print(\"Train - Mean Squared Error:\", mse_train)\n",
    "print(\"Test - R-squared Score:\", r2_test)\n",
    "print(\"Test - Mean Squared Error:\", mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - R-squared Score: 0.999981829502772\n",
      "Train - Mean Squared Error: 0.00013355400491181342\n",
      "Test - R-squared Score: -0.5963397615195354\n",
      "Test - Mean Squared Error: 13.873465277931324\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"Train - R-squared Score:\", r2_train)\n",
    "print(\"Train - Mean Squared Error:\", mse_train)\n",
    "print(\"Test - R-squared Score:\", r2_test)\n",
    "print(\"Test - Mean Squared Error:\", mse_test)\n",
    "\n",
    "r2_train_list.append(r2_train)\n",
    "r2_test_list.append(r2_test)\n",
    "mse_train_list.append(mse_train)\n",
    "mse_test_list.append(mse_test)\n",
    "rmse_train_list.append(rmse_train)\n",
    "rmse_test_list.append(rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CUSTOMER_ORDER_ID', 'SALES_ORG', 'DISTRIBUTION_CHANNEL', 'DIVISION',\n",
       "       'RELEASED_CREDIT_VALUE', 'PURCHASE_ORDER_TYPE', 'COMPANY_CODE',\n",
       "       'ORDER_CREATION_DATE', 'ORDER_CREATION_TIME', 'CREDIT_CONTROL_AREA',\n",
       "       'SOLD_TO_PARTY', 'ORDER_AMOUNT', 'REQUESTED_DELIVERY_DATE',\n",
       "       'ORDER_CURRENCY', 'CREDIT_STATUS', 'CUSTOMER_NUMBER', 'amount_in_usd',\n",
       "       'UNIQUE_CUST_ID', 'ORDER_MONTH', 'net_amount_in_usd', 'Last-1day_Sales',\n",
       "       'Last-2day_Sales', 'Last-3day_Sales', 'Last-4day_Sales',\n",
       "       'Last-5day_Sales', 'Last-6day_Sales', 'Last-7day_Sales',\n",
       "       'Last-1day_Diff', 'Last-2day_Diff', 'Last-3day_Diff', 'Last-4day_Diff',\n",
       "       'Last-5day_Diff', 'Last-6day_Diff', 'Last-7day_Diff',\n",
       "       'EXPECTED_DELIVERY_TIME', 'RELEASED_CREDIT_VALUE_LOG',\n",
       "       'Last-1day_Sales_log', 'Last-2day_Sales_log', 'Last-3day_Sales_log',\n",
       "       'Last-4day_Sales_log', 'Last-5day_Sales_log', 'Last-6day_Sales_log',\n",
       "       'Last-7day_Sales_log', 'amount_in_usd_log', 'net_amount_in_usd_log'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'n_estimators' : 800, #around 18-20 minutes 0.78 - 0.8\n",
    "#     'random_state': 42 \n",
    "# }\n",
    "# model = xgb.XGBRegressor(**params) #0.7659 - 0.7898 no params\n",
    "# # X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "# model.fit(X_train,y_train)\n",
    "# y_train_pred = model.predict(X_train)\n",
    "# y_test_pred = model.predict(X_test)\n",
    "\n",
    "# r2_train = r2_score(y_train, y_train_pred)\n",
    "# r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "# mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# print(\"Train - R-squared Score:\", r2_train)\n",
    "# print(\"Train - Mean Squared Error:\", mse_train)\n",
    "# print(\"Test - R-squared Score:\", r2_test)\n",
    "# print(\"Test - Mean Squared Error:\", mse_test)\n",
    "\n",
    "# r2_train_list.append(r2_train)\n",
    "# r2_test_list.append(r2_test)\n",
    "# mse_train_list.append(mse_train)\n",
    "# mse_test_list.append(mse_test)\n",
    "# rmse_train_list.append(rmse_train)\n",
    "# rmse_test_list.append(rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.132497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2979\n",
      "[LightGBM] [Info] Number of data points in the train set: 855281, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.583310\n",
      "Train - R-squared Score: 0.8147633141608892\n",
      "Train - Mean Squared Error: 1.3614983090502613\n",
      "Test - R-squared Score: 0.2936089058455621\n",
      "Test - Mean Squared Error: 6.139101808792215\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'num_leaves': 80, #80-100\n",
    "    'learning_rate': 0.05, #.06 -.07\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 6,#3-5\n",
    "    'verbose': 1\n",
    "}\n",
    "model = lgb.train(params,train_data,num_boost_round=1000)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"Train - R-squared Score:\", r2_train)\n",
    "print(\"Train - Mean Squared Error:\", mse_train)\n",
    "print(\"Test - R-squared Score:\", r2_test)\n",
    "print(\"Test - Mean Squared Error:\", mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - R-squared Score: 0.7815425261728309\n",
      "Train - Mean Squared Error: 1.6056726553260499\n",
      "Test - R-squared Score: 0.4208449204736099\n",
      "Test - Mean Squared Error: 5.033319397305885\n"
     ]
    }
   ],
   "source": [
    "print(\"Train - R-squared Score:\", r2_train)\n",
    "print(\"Train - Mean Squared Error:\", mse_train)\n",
    "print(\"Test - R-squared Score:\", r2_test)\n",
    "print(\"Test - Mean Squared Error:\", mse_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train - R-squared Score: 0.8474059308029369<br>\n",
    "Train - Mean Squared Error: 1.0296064647212406<br>\n",
    "Test - R-squared Score: 0.8224336004045232<br>\n",
    "Test - Mean Squared Error: 1.2411536841059796<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Dataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[127], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpmdarima\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marima\u001b[39;00m \u001b[39mimport\u001b[39;00m auto_arima\n\u001b[1;32m      3\u001b[0m data \u001b[39m=\u001b[39m train_data\n\u001b[0;32m----> 4\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mORDER_CREATION_DATE\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(data[\u001b[39m'\u001b[39;49m\u001b[39mORDER_CREATION_DATE\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      6\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mset_index(\u001b[39m'\u001b[39m\u001b[39mORDER_CREATION_DATE\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m time_series_data \u001b[39m=\u001b[39m data[\u001b[39m\"\u001b[39m\u001b[39mamount_in_usd\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Dataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pmdarima.arima import auto_arima\n",
    "data = train_data\n",
    "data['ORDER_CREATION_DATE'] = pd.to_datetime(data['ORDER_CREATION_DATE'])\n",
    "\n",
    "data = data.set_index('ORDER_CREATION_DATE')\n",
    "\n",
    "\n",
    "time_series_data = data[\"amount_in_usd\"]\n",
    "\n",
    "\n",
    "max_p = 5\n",
    "max_d = 2\n",
    "max_q = 5\n",
    "\n",
    "\n",
    "# Use auto_arima to determine the optimal values of p, d, and q\n",
    "model = auto_arima(time_series_data, start_p=1, d=None, start_q=1,\n",
    "                   max_p=max_p, max_d=max_d, max_q=max_q,\n",
    "                   seasonal=False, trace=True, error_action='ignore',\n",
    "                   suppress_warnings=True, stepwise=True)\n",
    "\n",
    "# Print the optimal values of p, d, and q\n",
    "print(\"Optimal values: p={}, d={}, q={}\".format(model.order[0], model.order[1], model.order[2]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
